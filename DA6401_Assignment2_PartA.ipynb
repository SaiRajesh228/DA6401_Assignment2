{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLLz4g1u8dkJ5XvW931Wpo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaiRajesh228/DA6401_Assignment2/blob/main/DA6401_Assignment2_PartA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t9da3j9P9cry"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "import wandb\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader,ChainDataset, ConcatDataset\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pbn9mjzl9tiI",
        "outputId": "60a70b9b-2ac4-4b7c-cbf9-2d231dd38147",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_image_dimensions(dataset):\n",
        "    \"\"\"\n",
        "    Analyzes and prints the minimum and maximum height and width of images in the provided dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset: A dataset object containing image samples, where each sample is a tuple (image_tensor, label).\n",
        "    \"\"\"\n",
        "    heights = []\n",
        "    widths = []\n",
        "\n",
        "    for idx in range(len(dataset)):\n",
        "        image_tensor, _ = dataset[idx]  # Extract image tensor and ignore the label\n",
        "        _, height, width = image_tensor.shape  # Assuming shape is (Channels, Height, Width)\n",
        "        heights.append(height)\n",
        "        widths.append(width)\n",
        "\n",
        "    print(f\"X min: {min(heights)}\\tX Max: {max(heights)}\")\n",
        "    print(f\"Y min: {min(widths)}\\tY Max: {max(widths)}\")"
      ],
      "metadata": {
        "id": "MgRrd4wn9qXr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CustomImageClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    End-to-end CNN implementation for image classification\n",
        "    Supports customizable convolutional and dense layers\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, conv_activation, fc_activation, conv_layers_config,\n",
        "                 hidden_dims, output_activation, use_conv_bn=False, use_fc_bn=False,\n",
        "                 dropout_rate=None, input_size=800, input_channels=3):\n",
        "        super().__init__()\n",
        "\n",
        "        # Spatial dimensions initialization\n",
        "        self.height = self.width = input_size\n",
        "        self.input_channels = input_channels\n",
        "\n",
        "        # Build convolutional blocks\n",
        "        self.conv_blocks = nn.ModuleList()\n",
        "        current_channels = input_channels\n",
        "\n",
        "        for config in conv_layers_config:\n",
        "            if config[0] == \"conv\":\n",
        "                _, filters, kernel, stride, padding = config\n",
        "                self.conv_blocks.append(nn.Conv2d(\n",
        "                    current_channels, filters, kernel, stride, padding\n",
        "                ))\n",
        "                if use_conv_bn:\n",
        "                    self.conv_blocks.append(nn.BatchNorm2d(filters))\n",
        "                self.conv_blocks.append(conv_activation())\n",
        "                current_channels = filters\n",
        "\n",
        "            elif config[0] == \"maxpool\":\n",
        "                _, kernel, stride = config\n",
        "                self.conv_blocks.append(nn.MaxPool2d(kernel, stride))\n",
        "\n",
        "        # Calculate flattened features size\n",
        "        final_h, final_w, final_ch = self._compute_conv_output(conv_layers_config)\n",
        "        flattened_size = final_h * final_w * final_ch\n",
        "\n",
        "        # Build dense layers\n",
        "        self.dense_layers = nn.ModuleList()\n",
        "        current_features = flattened_size\n",
        "\n",
        "        for hidden_dim in hidden_dims:\n",
        "            self.dense_layers.append(nn.Linear(current_features, hidden_dim))\n",
        "            if use_fc_bn:\n",
        "                self.dense_layers.append(nn.BatchNorm1d(hidden_dim))\n",
        "            self.dense_layers.append(fc_activation())\n",
        "            if dropout_rate:\n",
        "                self.dense_layers.append(nn.Dropout(dropout_rate))\n",
        "            current_features = hidden_dim\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = nn.Sequential(\n",
        "            nn.Linear(hidden_dims[-1], num_classes),\n",
        "            output_activation()\n",
        "        )\n",
        "\n",
        "        # Initialize weights\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _compute_conv_output(self, layer_configs):\n",
        "        \"\"\"Calculate final conv output dimensions\"\"\"\n",
        "        h = w = self.height\n",
        "        channels = self.input_channels\n",
        "        for config in layer_configs:\n",
        "            if config[0] == \"conv\":\n",
        "                _, filters, kernel, stride, padding = config\n",
        "                w = (w - kernel + 2*padding) // stride + 1\n",
        "                h = (h - kernel + 2*padding) // stride + 1\n",
        "                channels = filters\n",
        "            elif config[0] == \"maxpool\":\n",
        "                _, kernel, stride = config\n",
        "                w = (w - kernel) // stride + 1\n",
        "                h = (h - kernel) // stride + 1\n",
        "        return h, w, channels\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"Weight initialization\"\"\"\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(module.weight, nonlinearity='relu')\n",
        "                module.bias.data.fill_(0.01)\n",
        "            elif isinstance(module, nn.Linear):\n",
        "                nn.init.xavier_normal_(module.weight)\n",
        "                module.bias.data.fill_(0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.conv_blocks:\n",
        "            x = layer(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        for layer in self.dense_layers:\n",
        "            x = layer(x)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Instantiate model with example parameters\n",
        "model = CustomImageClassifier(\n",
        "    num_classes=10,\n",
        "    conv_activation=nn.ReLU,\n",
        "    fc_activation=nn.ReLU,\n",
        "    conv_layers_config=[\n",
        "        [\"conv\", 32, 3, 1, 1],\n",
        "        [\"maxpool\", 2, 2],\n",
        "        [\"conv\", 64, 3, 1, 1],\n",
        "        [\"maxpool\", 2, 2]\n",
        "    ],\n",
        "    hidden_dims=[512, 256],\n",
        "    output_activation=nn.Sigmoid,\n",
        "    input_size=800,\n",
        "    input_channels=3\n",
        ").to(device)\n",
        "\n",
        "# Verify model structure\n",
        "print(\"Model Architecture:\")\n",
        "print(model)\n",
        "\n",
        "# Test with sample input\n",
        "test_input = torch.randn(1, 3, 800, 800).to(device)\n",
        "print(\"\\nTest output shape:\", model(test_input).shape)"
      ],
      "metadata": {
        "id": "OmD0BAyq9uTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "\n",
        "class ImageDataManager:\n",
        "    \"\"\"Handles image dataset preparation with normalization and augmentation\"\"\"\n",
        "\n",
        "    def __init__(self, img_size, data_root, device, standardize=False):\n",
        "        self.img_size = img_size\n",
        "        self.data_root = data_root\n",
        "        self.device = device\n",
        "        self.standardize = standardize\n",
        "        self.mean, self.std = None, None\n",
        "\n",
        "    def _compute_stats(self, subset):\n",
        "        \"\"\"Calculate dataset mean/std for normalization\"\"\"\n",
        "        basic_transforms = transforms.Compose([\n",
        "            transforms.Resize(self.img_size),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "        dataset = datasets.ImageFolder(f\"{self.data_root}{subset}\", basic_transforms)\n",
        "        loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "        mean = torch.zeros(3).to(self.device)\n",
        "        std = torch.zeros(3).to(self.device)\n",
        "        total = 0\n",
        "\n",
        "        for images, _ in loader:\n",
        "            images = images.to(self.device)\n",
        "            batch = images.size(0)\n",
        "            images = images.view(batch, 3, -1)\n",
        "            mean += images.mean(2).sum(0)\n",
        "            std += images.var(2).sum(0)\n",
        "            total += batch\n",
        "\n",
        "        self.mean, self.std = (mean/total).cpu(), (torch.sqrt(std/total)).cpu()\n",
        "        return self.mean, self.std\n",
        "\n",
        "    def create_loader(self, subset, batch_size=32, augmentations=None):\n",
        "        \"\"\"Create configured dataloader for specified dataset subset\"\"\"\n",
        "        transforms_list = [\n",
        "            transforms.Resize(self.img_size),\n",
        "            transforms.ToTensor()\n",
        "        ]\n",
        "\n",
        "        if self.standardize:\n",
        "            if self.mean is None:\n",
        "                self._compute_stats(subset)\n",
        "            transforms_list.append(transforms.Normalize(self.mean, self.std))\n",
        "\n",
        "        if \"train\" in subset and augmentations:\n",
        "            datasets_list = []\n",
        "            datasets_list.append(datasets.ImageFolder(\n",
        "                f\"{self.data_root}{subset}\",\n",
        "                transforms.Compose(transforms_list)\n",
        "            ))\n",
        "            for aug in augmentations:\n",
        "                datasets_list.append(datasets.ImageFolder(\n",
        "                    f\"{self.data_root}{subset}\",\n",
        "                    transforms.Compose([*aug, *transforms_list])\n",
        "                ))\n",
        "            final_dataset = ConcatDataset(datasets_list)\n",
        "        else:\n",
        "            final_dataset = datasets.ImageFolder(\n",
        "                f\"{self.data_root}{subset}\",\n",
        "                transforms.Compose(transforms_list)\n",
        "            )\n",
        "\n",
        "        return DataLoader(\n",
        "            final_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=(\"train\" in subset),\n",
        "            num_workers=2,\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Initialize data manager\n",
        "    data_mgr = ImageDataManager(\n",
        "        img_size=(800, 800),\n",
        "        data_root=\"/content/data/\",  # Update with your path\n",
        "        device=device,\n",
        "        standardize=True\n",
        "    )\n",
        "\n",
        "    # Create dataloaders with example augmentations\n",
        "    train_loader = data_mgr.create_loader(\"train/\", batch_size=32,\n",
        "        augmentations=[[transforms.RandomHorizontalFlip()]])\n",
        "\n",
        "    val_loader = data_mgr.create_loader(\"val/\", batch_size=32)\n",
        "\n",
        "    # Test output\n",
        "    sample_batch = next(iter(train_loader))\n",
        "    print(f\"Batch shape: {sample_batch[0].shape}\")"
      ],
      "metadata": {
        "id": "3bxURpHKAEf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, ConcatDataset, RandomSampler\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class DLExperiment:\n",
        "    \"\"\"End-to-end deep learning pipeline for image classification\"\"\"\n",
        "\n",
        "    def __init__(self, img_size, data_root='/content/data/', device=None, use_wandb=False):\n",
        "        self.img_size = img_size\n",
        "        self.data_root = data_root\n",
        "        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.use_wandb = use_wandb\n",
        "        self.class_names = None\n",
        "\n",
        "    class ImageProcessor:\n",
        "        \"\"\"Handles dataset loading and preprocessing\"\"\"\n",
        "        def __init__(self, img_size, data_root, device):\n",
        "            self.img_size = img_size\n",
        "            self.data_root = data_root\n",
        "            self.device = device\n",
        "            self.mean, self.std = None, None\n",
        "\n",
        "        def _compute_stats(self, subset):\n",
        "            transform = transforms.Compose([\n",
        "                transforms.Resize(self.img_size),\n",
        "                transforms.ToTensor()\n",
        "            ])\n",
        "            dataset = datasets.ImageFolder(self.data_root + subset, transform=transform)\n",
        "            loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "            mean = torch.zeros(3).to(self.device)\n",
        "            std = torch.zeros(3).to(self.device)\n",
        "            total = 0\n",
        "\n",
        "            for images, _ in loader:\n",
        "                images = images.to(self.device)\n",
        "                batch = images.size(0)\n",
        "                images = images.view(batch, 3, -1)\n",
        "                mean += images.mean(2).sum(0)\n",
        "                std += images.var(2).sum(0)\n",
        "                total += batch\n",
        "\n",
        "            return (mean/total).cpu(), (torch.sqrt(std/total)).cpu()\n",
        "\n",
        "        def get_loader(self, subset, batch_size=32, augmentations=None):\n",
        "            transforms_list = [\n",
        "                transforms.Resize(self.img_size),\n",
        "                transforms.ToTensor()\n",
        "            ]\n",
        "\n",
        "            if self.mean is None:\n",
        "                self.mean, self.std = self._compute_stats(subset)\n",
        "            transforms_list.append(transforms.Normalize(self.mean, self.std))\n",
        "\n",
        "            if \"train\" in subset and augmentations:\n",
        "                dataset_list = [datasets.ImageFolder(\n",
        "                    self.data_root+subset,\n",
        "                    transforms.Compose(transforms_list)\n",
        "                )]\n",
        "                for aug in augmentations:\n",
        "                    dataset_list.append(datasets.ImageFolder(\n",
        "                        self.data_root+subset,\n",
        "                        transforms.Compose(aug + transforms_list)\n",
        "                    ))\n",
        "                final_dataset = ConcatDataset(dataset_list)\n",
        "            else:\n",
        "                final_dataset = datasets.ImageFolder(\n",
        "                    self.data_root+subset,\n",
        "                    transforms.Compose(transforms_list)\n",
        "                )\n",
        "\n",
        "            return DataLoader(\n",
        "                final_dataset,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=(\"train\" in subset),\n",
        "                num_workers=2,\n",
        "                pin_memory=True\n",
        "            )\n",
        "\n",
        "    class CNNModel(nn.Module):\n",
        "        \"\"\"Customizable CNN architecture\"\"\"\n",
        "        def __init__(self, input_size, in_channels, num_classes, conv_layers, fc_layers):\n",
        "            super().__init__()\n",
        "            self.features = nn.ModuleList()\n",
        "            current_channels = in_channels\n",
        "            h, w = input_size\n",
        "\n",
        "            for layer in conv_layers:\n",
        "                if layer['type'] == 'conv':\n",
        "                    self.features.append(nn.Conv2d(\n",
        "                        current_channels, layer['filters'], layer['kernel'],\n",
        "                        layer['stride'], layer['padding']\n",
        "                    ))\n",
        "                    if layer['bn']: self.features.append(nn.BatchNorm2d(layer['filters']))\n",
        "                    self.features.append(self._get_activation(layer['activation']))\n",
        "                    current_channels = layer['filters']\n",
        "                    h = (h - layer['kernel'] + 2*layer['padding'])//layer['stride'] + 1\n",
        "                    w = (w - layer['kernel'] + 2*layer['padding'])//layer['stride'] + 1\n",
        "                elif layer['type'] == 'pool':\n",
        "                    self.features.append(nn.MaxPool2d(layer['size'], layer['stride']))\n",
        "                    h = (h - layer['size'])//layer['stride'] + 1\n",
        "                    w = (w - layer['size'])//layer['stride'] + 1\n",
        "\n",
        "            self.classifier = nn.ModuleList()\n",
        "            in_features = h * w * current_channels\n",
        "            for units in fc_layers:\n",
        "                self.classifier.append(nn.Linear(in_features, units))\n",
        "                self.classifier.append(self._get_activation('relu'))\n",
        "                if layer['dropout']: self.classifier.append(nn.Dropout(layer['dropout']))\n",
        "                in_features = units\n",
        "\n",
        "            self.output = nn.Linear(in_features, num_classes)\n",
        "            self._init_weights()\n",
        "\n",
        "        def _get_activation(self, name):\n",
        "            return {'relu': nn.ReLU(), 'sigmoid': nn.Sigmoid()}[name.lower()]\n",
        "\n",
        "        def _init_weights(self):\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Conv2d):\n",
        "                    nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                    if m.bias is not None: m.bias.data.zero_()\n",
        "                elif isinstance(m, nn.Linear):\n",
        "                    nn.init.xavier_normal_(m.weight)\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "        def forward(self, x):\n",
        "            for layer in self.features: x = layer(x)\n",
        "            x = torch.flatten(x, 1)\n",
        "            for layer in self.classifier: x = layer(x)\n",
        "            return self.output(x)\n",
        "\n",
        "    def setup_data(self, batch_size=32, augmentations=None):\n",
        "        \"\"\"Initialize data loaders\"\"\"\n",
        "        processor = self.ImageProcessor(self.img_size, self.data_root, self.device)\n",
        "        self.train_loader = processor.get_loader('train/', batch_size, augmentations)\n",
        "        self.val_loader = processor.get_loader('val/', batch_size)\n",
        "        self.test_loader = processor.get_loader('test/', batch_size)\n",
        "        self.class_names = self.train_loader.dataset.classes\n",
        "        return self.train_loader, self.val_loader, self.test_loader\n",
        "\n",
        "    def setup_model(self, conv_config, fc_config, num_classes):\n",
        "        \"\"\"Initialize CNN model\"\"\"\n",
        "        self.model = self.CNNModel(\n",
        "            input_size=self.img_size,\n",
        "            in_channels=3,\n",
        "            num_classes=num_classes,\n",
        "            conv_layers=conv_config,\n",
        "            fc_layers=fc_config\n",
        "        ).to(self.device)\n",
        "        return self.model\n",
        "\n",
        "    def train_model(self, epochs=10, lr=1e-3, weight_decay=1e-4):\n",
        "        \"\"\"Training workflow\"\"\"\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        best_acc = 0.0\n",
        "        for epoch in tqdm(range(epochs)):\n",
        "            self.model.train()\n",
        "            running_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            for inputs, labels in self.train_loader:\n",
        "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self.model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            train_loss = running_loss / total\n",
        "            train_acc = 100 * correct / total\n",
        "            val_loss, val_acc = self.evaluate(self.val_loader)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "            print(f\"Train Loss: {train_loss:.4f} | Acc: {train_acc:.2f}%\")\n",
        "            print(f\"Val Loss: {val_loss:.4f} | Acc: {val_acc:.2f}%\")\n",
        "\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                torch.save(self.model.state_dict(), 'best_model.pth')\n",
        "\n",
        "    def evaluate(self, loader):\n",
        "        \"\"\"Model evaluation\"\"\"\n",
        "        self.model.eval()\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        loss = 0.0\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in loader:\n",
        "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(inputs)\n",
        "                loss += criterion(outputs, labels).item() * inputs.size(0)\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        return loss/total, 100*correct/total\n",
        "\n",
        "    def visualize_predictions(self, num_images=9):\n",
        "        \"\"\"Sample predictions visualization\"\"\"\n",
        "        self.model.eval()\n",
        "        sampler = RandomSampler(self.test_loader.dataset)\n",
        "        sample_loader = DataLoader(self.test_loader.dataset, batch_size=num_images, sampler=sampler)\n",
        "        images, labels = next(iter(sample_loader))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(images.to(self.device))\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        plt.figure(figsize=(12, 12))\n",
        "        for i in range(num_images):\n",
        "            plt.subplot(3, 3, i+1)\n",
        "            image = images[i].permute(1, 2, 0).cpu().numpy()\n",
        "            plt.imshow(np.clip(image, 0, 1))\n",
        "            color = 'green' if preds[i] == labels[i] else 'red'\n",
        "            plt.title(f\"True: {self.class_names[labels[i]]}\\nPred: {self.class_names[preds[i]]}\", color=color)\n",
        "            plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Example usage in Colab:\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize experiment\n",
        "    exp = DLExperiment(img_size=(600, 600), data_root='/content/data/')\n",
        "\n",
        "    # Define layer configurations\n",
        "    conv_config = [\n",
        "        {'type': 'conv', 'filters': 32, 'kernel': 3, 'stride': 1, 'padding': 1, 'activation': 'relu', 'bn': True},\n",
        "        {'type': 'pool', 'size': 2, 'stride': 2},\n",
        "        {'type': 'conv', 'filters': 64, 'kernel': 3, 'stride': 1, 'padding': 1, 'activation': 'relu', 'bn': True},\n",
        "        {'type': 'pool', 'size': 2, 'stride': 2}\n",
        "    ]\n",
        "\n",
        "    fc_config = [512, 256]\n",
        "\n",
        "    # Setup data and model\n",
        "    exp.setup_data(batch_size=32)\n",
        "    exp.setup_model(conv_config, fc_config, num_classes=10)\n",
        "\n",
        "    # Start training\n",
        "    exp.train_model(epochs=10, lr=1e-3)\n",
        "\n",
        "    # Evaluate and visualize\n",
        "    test_loss, test_acc = exp.evaluate(exp.test_loader)\n",
        "    print(f\"\\nFinal Test Accuracy: {test_acc:.2f}%\")\n",
        "    exp.visualize_predictions()"
      ],
      "metadata": {
        "id": "83hql0F2BVdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login(key=\"\")\n",
        "\n",
        "\n",
        "sweep_config = {\n",
        "    'method': 'random',\n",
        "    'name' : 'PA2 Hyper Sweep Factor Two',\n",
        "    'metric': {\n",
        "      'name': 'Validation accuracy',\n",
        "      'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'num_hidden_layers': {\n",
        "            'values': [1]\n",
        "        },\n",
        "         'hidden_size':{\n",
        "            'values':[32,64,128,256]\n",
        "        },\n",
        "        'activation': {\n",
        "            'values': ['relu','silu','tanh']\n",
        "        },\n",
        "\n",
        "        'optimiser': {\n",
        "            'values': [\"adam\",\"rmsprop\",\"nadam\"]\n",
        "        },\n",
        "\n",
        "        'num_conv_layers' :{\n",
        "            'values' : [5]\n",
        "        },\n",
        "\n",
        "        'conv_filter_factor':{\n",
        "            'values' : [2]\n",
        "        },\n",
        "\n",
        "        'num_filters':{\n",
        "            'values' : [4,8,16]\n",
        "        },\n",
        "\n",
        "        'filter_size':{\n",
        "            'values' : [5,7,11]\n",
        "        },\n",
        "\n",
        "\n",
        "        'lr': {\n",
        "            'values': [1e-3,1e-4,3e-4]\n",
        "        },\n",
        "        'weight_decay': {\n",
        "            'values': [0,5e-3,5e-4]\n",
        "        },\n",
        "\n",
        "        'batch_norm' : {\n",
        "            'values' : [True, False]\n",
        "        },\n",
        "\n",
        "        'dropout' : {\n",
        "\n",
        "            'values' : [None,0.2,0.3]\n",
        "        },\n",
        "\n",
        "        'data_aug' : {\n",
        "\n",
        "            'values' : [None,1,2]\n",
        "        },\n",
        "\n",
        "        'epochs' : {\n",
        "\n",
        "            'values' : [8]\n",
        "        },\n",
        "\n",
        "        'Image_Crop_Size':{\n",
        "            'values' : [500,600,800]\n",
        "        },\n",
        "\n",
        "        'batch_size' : {\n",
        "\n",
        "            'values' : [16,32]\n",
        "        }\n",
        "\n",
        "        }\n",
        "    }\n",
        "\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='')"
      ],
      "metadata": {
        "id": "aH1EaPaNB_qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def configure_image_experiment(config, data_root=\"inaturalist_12K/\", model_checkpoint=None, use_wandb=False):\n",
        "    \"\"\"Configure and execute complete image classification workflow\"\"\"\n",
        "\n",
        "    # Device setup\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using hardware accelerator: {device}\")\n",
        "\n",
        "    # Initialize experiment manager\n",
        "    experiment = DLExperiment(\n",
        "        img_size=(config['crop_size'], config['crop_size']),\n",
        "        data_root=data_root,\n",
        "        device=device,\n",
        "        use_wandb=use_wandb\n",
        "    )\n",
        "\n",
        "    # Configure data augmentations\n",
        "    augmentation_presets = []\n",
        "    if config['data_aug']:\n",
        "        augmentations = [\n",
        "            [transforms.RandomPerspective(p=1)],\n",
        "            [transforms.ColorJitter(brightness=0.5, hue=0.5)]\n",
        "        ]\n",
        "        augmentation_presets = augmentations[:config['data_aug']]\n",
        "\n",
        "    # Initialize data pipelines\n",
        "    train_loader, val_loader, test_loader = experiment.setup_data(\n",
        "        batch_size=config['batch_size'],\n",
        "        augmentations=augmentation_presets\n",
        "    )\n",
        "\n",
        "    # Load existing model if provided\n",
        "    if model_checkpoint:\n",
        "        experiment.model.load_state_dict(torch.load(model_checkpoint))\n",
        "        test_loss, test_acc = experiment.evaluate(test_loader)\n",
        "        print(f\"Loaded model test accuracy: {test_acc:.2f}%\")\n",
        "        return experiment.model\n",
        "\n",
        "    # Configure convolutional architecture\n",
        "    conv_settings = []\n",
        "    current_filters = config['initial_filters']\n",
        "    for layer_idx in range(config['conv_layers']):\n",
        "        conv_settings.append({\n",
        "            'type': 'conv',\n",
        "            'filters': current_filters,\n",
        "            'kernel': config['kernel_size'],\n",
        "            'stride': 2 if layer_idx > 0 else 1,\n",
        "            'padding': (config['kernel_size']-1) if layer_idx == 0 else 0,\n",
        "            'activation': 'relu',\n",
        "            'bn': config['batch_norm']\n",
        "        })\n",
        "        conv_settings.append({\n",
        "            'type': 'pool',\n",
        "            'size': 2,\n",
        "            'stride': 1\n",
        "        })\n",
        "        current_filters *= config['filter_growth_factor']\n",
        "\n",
        "    # Configure fully connected layers\n",
        "    fc_settings = [config['hidden_units']] * config['dense_layers']\n",
        "\n",
        "    # Initialize model architecture\n",
        "    experiment.setup_model(\n",
        "        conv_config=conv_settings,\n",
        "        fc_config=fc_settings,\n",
        "        num_classes=len(train_loader.dataset.classes)\n",
        "    )\n",
        "\n",
        "    # Execute training workflow\n",
        "    experiment.train_model(\n",
        "        epochs=config['training_epochs'],\n",
        "        lr=config['learning_rate'],\n",
        "        weight_decay=config['l2_regularization']\n",
        "    )\n",
        "\n",
        "    return experiment.model\n",
        "\n",
        "# Example configuration dictionary\n",
        "sample_config = {\n",
        "    'crop_size': 224,\n",
        "    'batch_size': 64,\n",
        "    'data_aug': 2,\n",
        "    'conv_layers': 4,\n",
        "    'initial_filters': 32,\n",
        "    'kernel_size': 3,\n",
        "    'filter_growth_factor': 2,\n",
        "    'dense_layers': 2,\n",
        "    'hidden_units': 512,\n",
        "    'batch_norm': True,\n",
        "    'dropout_rate': 0.5,\n",
        "    'learning_rate': 1e-3,\n",
        "    'l2_regularization': 1e-4,\n",
        "    'training_epochs': 25\n",
        "}\n",
        "\n",
        "# Example execution\n",
        "if __name__ == \"__main__\":\n",
        "    model = configure_image_experiment(sample_config)\n",
        "    model.visualize_predictions()"
      ],
      "metadata": {
        "id": "zmVHHFZiCDxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_model_config = {\n",
        "    # Network Architecture\n",
        "    'dense_layers': 1,               # Previously num_hidden_layers\n",
        "    'hidden_units': 64,              # Previously hidden_size\n",
        "    'activation': 'relu',            # Unchanged\n",
        "    'optimizer': 'rmsprop',          # Previously optimiser\n",
        "\n",
        "    # Convolutional Parameters\n",
        "    'conv_layers': 5,                # Previously num_conv_layers\n",
        "    'filter_growth_factor': 1,       # Previously conv_filter_factor\n",
        "    'initial_filters': 32,           # Previously num_filters\n",
        "    'kernel_size': 5,                # Previously filter_size\n",
        "\n",
        "    # Training Parameters\n",
        "    'learning_rate': 3e-4,           # Previously lr\n",
        "    'l2_regularization': 5e-4,       # Previously weight_decay\n",
        "    'batch_norm': True,              # Unchanged\n",
        "    'dropout_rate': 0.2,             # Previously dropout\n",
        "\n",
        "    # Data Configuration\n",
        "    'data_aug': 1,                   # Unchanged\n",
        "    'training_epochs': 8,            # Previously epochs\n",
        "    'crop_size': 600,                # Previously Image_Crop_Size\n",
        "    'batch_size': 16                 # Unchanged\n",
        "}"
      ],
      "metadata": {
        "id": "hda2WP56ClQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To run with best parameters and load existing model\n",
        "configure_image_experiment(\n",
        "    config=optimized_model_config,\n",
        "    model_checkpoint=\"best_model.pth\",  # Updated parameter name\n",
        "    data_root=\"/content/inaturalist_12K/\",  # Explicit path for Colab\n",
        "    use_wandb=False\n",
        ")\n",
        "\n",
        "# To train from scratch with best parameters\n",
        "configure_image_experiment(\n",
        "    config=optimized_model_config,\n",
        "    data_root=\"/content/inaturalist_12K/\",\n",
        "    use_wandb=True\n",
        ")"
      ],
      "metadata": {
        "id": "24W68_R7Efec"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}